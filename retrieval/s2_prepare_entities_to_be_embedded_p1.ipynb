{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183834ac-efae-4bc9-95c8-e0ffd2bd0cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a995ab12",
   "metadata": {},
   "source": [
    "## check extracted entities from questions by Claude Sonnet 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f6c3f8-b3f5-47f3-9c7d-7e692d75a850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define your S3 bucket and file key\n",
    "bucket_name = 'sagemaker-studio-423623869859-3no3d9ie4hx'\n",
    "file_key = 'extracted_entities_in_questions_train.json'  # replace with your actual file path\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Load the file from S3\n",
    "obj = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n",
    "questions_entities = json.load(obj['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5ba44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6962"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be0c489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = list(questions_entities.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b32110d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many heads of the departments are older than 56 ?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56d26868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities_for_tables': ['departments'],\n",
       " 'entities_for_columns': ['heads', 'age']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_entities[questions[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bad6896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(questions_entities[questions[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c8b160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in questions_entities:\n",
    "    if questions_entities[key] == {}:\n",
    "        print(questions_entities[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e203bea",
   "metadata": {},
   "source": [
    "## There are duplicated questions in the original training data, some of the SQL query answers are different for the same question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "569ba435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many users are there?\n",
      "2\n",
      "['SELECT count(*) FROM user_profiles', 'SELECT count(*) FROM useracct']\n",
      "How many employees do we have?\n",
      "3\n",
      "['SELECT count(*) FROM Employee', 'SELECT count(*) FROM Employees;', 'SELECT count(*) FROM Employees']\n",
      "How many students are there?\n",
      "4\n",
      "['SELECT count(*) FROM Student', 'SELECT count(*) FROM list', 'SELECT count(*) FROM student', 'SELECT count(*) FROM student']\n",
      "How many students does each advisor have?\n",
      "2\n",
      "['SELECT advisor ,  count(*) FROM Student GROUP BY advisor', 'SELECT Advisor ,  count(*) FROM STUDENT GROUP BY Advisor']\n",
      "How many accounts do we have?\n",
      "2\n",
      "['SELECT count(*) FROM Accounts', 'SELECT count(*) FROM Accounts']\n",
      "Count the number of accounts.\n",
      "3\n",
      "['SELECT count(*) FROM Accounts', 'SELECT count(*) FROM accounts', 'SELECT count(*) FROM Accounts']\n",
      "How many customers do we have?\n",
      "2\n",
      "['SELECT count(*) FROM Customers', 'SELECT count(*) FROM CUSTOMERS']\n",
      "Count the number of customers.\n",
      "3\n",
      "['SELECT count(*) FROM Customers', 'SELECT count(*) FROM Customers', 'SELECT count(*) FROM customers']\n",
      "How many services are there?\n",
      "2\n",
      "['SELECT count(*) FROM services', 'SELECT count(*) FROM services']\n",
      "Count the number of countries.\n",
      "2\n",
      "['SELECT count(*) FROM country', 'SELECT count(*) FROM county_public_safety']\n",
      "Find the name of the courses that do not have any prerequisite?\n",
      "2\n",
      "['SELECT title FROM course WHERE course_id NOT IN (SELECT course_id FROM prereq)', 'SELECT title FROM course WHERE course_id NOT IN (SELECT course_id FROM prereq)']\n",
      "How many students are in each department?\n",
      "2\n",
      "['SELECT count(*) ,  dept_name FROM student GROUP BY dept_name', 'SELECT count(*) ,  dept_code FROM student GROUP BY dept_code']\n",
      "Count the number of artists.\n",
      "2\n",
      "['SELECT count(*) FROM artist', 'SELECT count(*) FROM artist']\n",
      "Find the names of users who did not leave any review.\n",
      "2\n",
      "['SELECT name FROM useracct WHERE u_id NOT IN (SELECT u_id FROM review)', 'SELECT name FROM useracct WHERE u_id NOT IN (SELECT u_id FROM review)']\n",
      "How many schools are there?\n",
      "2\n",
      "['SELECT count(*) FROM school', 'SELECT count(*) FROM school']\n",
      "Count the number of schools.\n",
      "2\n",
      "['SELECT count(*) FROM school', 'SELECT count(*) FROM school']\n",
      "How many regions do we have?\n",
      "2\n",
      "['SELECT count(*) FROM region', 'SELECT count(*) FROM region']\n",
      "Count the number of regions.\n",
      "2\n",
      "['SELECT count(*) FROM region', 'SELECT count(*) FROM region']\n",
      "What is the id and last name of the driver who participated in the most races after 2010?\n",
      "2\n",
      "['SELECT T1.driverid ,  T1.surname FROM drivers AS T1 JOIN results AS T2 ON T1.driverid  =  T2.driverid JOIN races AS T3 ON T2.raceid = T3.raceid WHERE T3.year > 2010 GROUP BY T1.driverid ORDER BY count(*) DESC LIMIT 1', 'SELECT T1.driverid ,  T1.surname FROM drivers AS T1 JOIN results AS T2 ON T1.driverid  =  T2.driverid JOIN races AS T3 ON T2.raceid = T3.raceid WHERE T3.year > 2010 GROUP BY T1.driverid ORDER BY count(*) DESC LIMIT 1']\n",
      "Find the count of universities whose campus fee is greater than the average campus fee.\n",
      "2\n",
      "['SELECT count(*) FROM csu_fees WHERE campusfee  >  (SELECT avg(campusfee) FROM csu_fees)', 'SELECT count(*) FROM csu_fees WHERE campusfee  >  (SELECT avg(campusfee) FROM csu_fees)']\n",
      "How many movies were made before 2000?\n",
      "2\n",
      "['SELECT count(*) FROM Movie WHERE YEAR  <  2000', 'SELECT count(*) FROM Movie WHERE YEAR  <  2000']\n",
      "Find the payment method that is used most frequently.\n",
      "2\n",
      "['SELECT payment_method FROM Customers GROUP BY payment_method ORDER BY count(*) DESC LIMIT 1', 'SELECT payment_method FROM customers GROUP BY payment_method ORDER BY count(*) DESC LIMIT 1']\n",
      "How many customers are there?\n",
      "4\n",
      "['SELECT sum(no_of_customers) FROM bank', 'SELECT count(*) FROM customers', 'SELECT count(*) FROM customers', 'SELECT count(*) FROM Customers;']\n",
      "How many clubs are there?\n",
      "2\n",
      "['SELECT count(*) FROM club', 'SELECT count(*) FROM club']\n",
      "What is all the information about the Marketing department?\n",
      "2\n",
      "[\"SELECT * FROM  departments WHERE department_name  =  'Marketing'\", \"SELECT * FROM  departments WHERE department_name  =  'Marketing'\"]\n",
      "display the ID for those employees who did two or more jobs in the past.\n",
      "2\n",
      "['SELECT employee_id FROM job_history GROUP BY employee_id HAVING COUNT(*)  >= 2', 'SELECT employee_id FROM job_history GROUP BY employee_id HAVING COUNT(*)  >= 2']\n",
      "display the department name and number of employees in each of the department.\n",
      "2\n",
      "['SELECT T2.department_name ,  COUNT(*) FROM employees AS T1 JOIN departments AS T2 ON T1.department_id  =  T2.department_id GROUP BY T2.department_name', 'SELECT department_name ,  COUNT(*) FROM employees AS T1 JOIN departments AS T2 ON T1.department_id  =  T2.department_id GROUP BY department_name']\n",
      "How many courses are there in total?\n",
      "2\n",
      "['SELECT count(*) FROM COURSES', 'SELECT count(*) FROM COURSE']\n",
      "Find the number of students in total.\n",
      "2\n",
      "['SELECT count(*) FROM list', 'SELECT count(*) FROM STUDENT']\n",
      "How many friends does Dan have?\n",
      "2\n",
      "[\"SELECT count(T2.friend) FROM Person AS T1 JOIN PersonFriend AS T2 ON T1.name  =  T2.name WHERE T1.name  =  'Dan'\", \"SELECT count(T2.friend) FROM Person AS T1 JOIN PersonFriend AS T2 ON T1.name  =  T2.name WHERE T1.name  =  'Dan'\"]\n",
      "How many products are there?\n",
      "2\n",
      "['SELECT count(*) FROM Products', 'SELECT count(*) FROM products']\n"
     ]
    }
   ],
   "source": [
    "obj = s3_client.get_object(Bucket=bucket_name, Key='train_spider.json')\n",
    "spider_train = json.load(obj['Body'])\n",
    "\n",
    "question_query = {}\n",
    "\n",
    "for dic in spider_train:\n",
    "    question = dic['question']\n",
    "    query = dic['query']\n",
    "    question_query[question] = question_query.get(question, []) + [query]\n",
    "\n",
    "for question in question_query:\n",
    "    list_of_queries = question_query[question]\n",
    "    if len(list_of_queries) > 1:\n",
    "        print(question)\n",
    "        print(len(list_of_queries))\n",
    "        print(list_of_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65c9701b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6962"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efa22bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6962"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c037a3",
   "metadata": {},
   "source": [
    "### Make sure the questions in the entity extraction task are the original questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9230407a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(questions_entities.keys()) == list(question_query.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c89f1",
   "metadata": {},
   "source": [
    "## collect all things to be embedded by BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a6d2eb",
   "metadata": {},
   "source": [
    "### questions and extracted entities from questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35e78d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6962\n",
      "3572\n"
     ]
    }
   ],
   "source": [
    "questions, entities = {}, {}\n",
    "\n",
    "for question in questions_entities:\n",
    "    \n",
    "    questions[question] = None\n",
    "    \n",
    "    for key in questions_entities[question]:\n",
    "        for entity in questions_entities[question][key]:\n",
    "            entities[entity] = None\n",
    "        \n",
    "print(len(questions))\n",
    "print(len(entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7783998f",
   "metadata": {},
   "source": [
    "### Get database names, table names, and schemas for each table. For each schema file, identity the \"create table table_name (...)\" structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a24f03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed schemas saved to s3://sagemaker-studio-423623869859-3no3d9ie4hx/database_parsed_schemas.json\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# S3 bucket and folder\n",
    "bucket_name = 'sagemaker-studio-423623869859-3no3d9ie4hx'\n",
    "base_folder = 'database/'\n",
    "\n",
    "# Regular expression to identify CREATE TABLE structures with matching brackets\n",
    "table_regex = re.compile(r'CREATE TABLE [\"`]?(\\w+)[\"`]?\\s*\\((.*?)\\);', re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "# Function to find and extract entire CREATE TABLE definitions\n",
    "def extract_table_definitions(sql_content):\n",
    "    tables = {}\n",
    "    # Find all matches for CREATE TABLE structures\n",
    "    for match in table_regex.finditer(sql_content):\n",
    "        table_name = match.group(1)\n",
    "        table_definition = f\"CREATE TABLE {table_name} ({match.group(2)});\"\n",
    "        tables[table_name] = table_definition\n",
    "    return tables\n",
    "\n",
    "# S3 interaction: Fetch all SQL content from schema files, parse, and save the results\n",
    "def get_schema_files_and_parse(bucket, folder):\n",
    "    result = s3.list_objects_v2(Bucket=bucket, Prefix=folder)\n",
    "    all_schemas = {}\n",
    "\n",
    "    for item in result.get('Contents', []):\n",
    "        if item['Key'].endswith('schema.sql'):\n",
    "            # Download the SQL content from S3\n",
    "            sql_content = s3.get_object(Bucket=bucket, Key=item['Key'])['Body'].read().decode('utf-8')\n",
    "            \n",
    "            # Parse tables and their definitions\n",
    "            schema = extract_table_definitions(sql_content)\n",
    "            \n",
    "            # Extract the subfolder name and add schema with placeholder for subfolder name\n",
    "            subfolder_name = item['Key'].split('/')[-2]\n",
    "            all_schemas[subfolder_name] = schema or {}\n",
    "\n",
    "    # Save the result as a JSON file and upload to S3\n",
    "    output_key = 'database_parsed_schemas.json'\n",
    "    output_json = json.dumps(all_schemas, indent=4)\n",
    "    s3.put_object(Bucket=bucket, Key=output_key, Body=output_json)\n",
    "    print(f\"Parsed schemas saved to s3://{bucket}/{output_key}\")\n",
    "\n",
    "# Run the function\n",
    "get_schema_files_and_parse(bucket_name, base_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6f98684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_index = 100\n",
    "# table_index = 0\n",
    "# column_index = 3\n",
    "\n",
    "# folders = list(all_schemas.keys())\n",
    "# folder = folders[folder_index]\n",
    "# print(folders)\n",
    "# print(folder)\n",
    "# print('\\n')\n",
    "\n",
    "# tables = list(all_schemas[folder].keys())\n",
    "# table = tables[table_index]\n",
    "# print(tables)\n",
    "# print(table)\n",
    "# print('\\n')\n",
    "\n",
    "# columns = all_schemas[folder][table]\n",
    "# column = columns[column_index]\n",
    "# print(columns)\n",
    "# print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff8b2cc",
   "metadata": {},
   "source": [
    "### There are 166 subfolders but only 148 of them have schema.sql files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcbe2a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sub-folders in 'sagemaker-studio-423623869859-3no3d9ie4hx' under 'database/': 166\n"
     ]
    }
   ],
   "source": [
    "folder_prefix = 'database/'  # Specify the folder within the bucket\n",
    "\n",
    "def count_subfolders(bucket, prefix):\n",
    "    # Use list_objects_v2 with the Delimiter to identify subfolders\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix, Delimiter='/')\n",
    "    \n",
    "    # Extract common prefixes (subfolder names)\n",
    "    subfolders = response.get('CommonPrefixes', [])\n",
    "    \n",
    "    # Count the subfolders\n",
    "    return len(subfolders)\n",
    "\n",
    "# Count and print the number of subfolders\n",
    "total_subfolders = count_subfolders(bucket_name, folder_prefix)\n",
    "print(f\"Total number of sub-folders in '{bucket_name}' under '{folder_prefix}': {total_subfolders}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77cc85d",
   "metadata": {},
   "source": [
    "### Inspect parsed schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3893b052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subfolder: academic\n",
      "  Table: author\n",
      "    Definition: CREATE TABLE author (\n",
      "\"aid\" int,\n",
      "\"homepage\" text,\n",
      "\"name\" text,\n",
      "\"oid\" int,\n",
      "primary key(\"aid\")\n",
      ");\n",
      "  Table: conference\n",
      "    Definition: CREATE TABLE conference (\n",
      "\"cid\" int,\n",
      "\"homepage\" text,\n",
      "\"name\" text,\n",
      "primary key (\"cid\")\n",
      ");\n",
      "  Table: domain\n",
      "    Definition: CREATE TABLE domain (\n",
      "\"did\" int,\n",
      "\"name\" text,\n",
      "primary key (\"did\")\n",
      ");\n",
      "  Table: domain_author\n",
      "    Definition: CREATE TABLE domain_author (\n",
      "\"aid\" int, \n",
      "\"did\" int,\n",
      "primary key (\"did\", \"aid\"),\n",
      "foreign key(\"aid\") references `author`(\"aid\"),\n",
      "foreign key(\"did\") references `domain`(\"did\")\n",
      ");\n",
      "  Table: domain_conference\n",
      "    Definition: CREATE TABLE domain_conference (\n",
      "\"cid\" int,\n",
      "\"did\" int,\n",
      "primary key (\"did\", \"cid\"),\n",
      "foreign key(\"cid\") references `conference`(\"cid\"),\n",
      "foreign key(\"did\") references `domain`(\"did\")\n",
      ");\n",
      "  Table: journal\n",
      "    Definition: CREATE TABLE journal (\n",
      "\"homepage\" text,\n",
      "\"jid\" int,\n",
      "\"name\" text,\n",
      "primary key(\"jid\")\n",
      ");\n",
      "  Table: domain_journal\n",
      "    Definition: CREATE TABLE domain_journal (\n",
      "\"did\" int,\n",
      "\"jid\" int,\n",
      "primary key (\"did\", \"jid\"),\n",
      "foreign key(\"jid\") references \"journal\"(\"jid\"),\n",
      "foreign key(\"did\") references \"domain\"(\"did\")\n",
      ");\n",
      "  Table: keyword\n",
      "    Definition: CREATE TABLE keyword (\n",
      "\"keyword\" text,\n",
      "\"kid\" int,\n",
      "primary key(\"kid\")\n",
      ");\n",
      "  Table: domain_keyword\n",
      "    Definition: CREATE TABLE domain_keyword (\n",
      "\"did\" int,\n",
      "\"kid\" int,\n",
      "primary key (\"did\", \"kid\"),\n",
      "foreign key(\"kid\") references \"keyword\"(\"kid\"),\n",
      "foreign key(\"did\") references \"domain\"(\"did\")\n",
      ");\n",
      "  Table: publication\n",
      "    Definition: CREATE TABLE publication (\n",
      "\"abstract\" text,\n",
      "\"cid\" text,\n",
      "\"citation_num\" int,\n",
      "\"jid\" int,\n",
      "\"pid\" int,\n",
      "\"reference_num\" int,\n",
      "\"title\" text,\n",
      "\"year\" int,\n",
      "primary key(\"pid\"),\n",
      "foreign key(\"jid\") references \"journal\"(\"jid\"),\n",
      "foreign key(\"cid\") references \"conference\"(\"cid\")\n",
      ");\n",
      "  Table: domain_publication\n",
      "    Definition: CREATE TABLE domain_publication (\n",
      "\"did\" int,\n",
      "\"pid\" int,\n",
      "primary key (\"did\", \"pid\"),\n",
      "foreign key(\"pid\") references \"publication\"(\"pid\"),\n",
      "foreign key(\"did\") references \"domain\"(\"did\")\n",
      ");\n",
      "  Table: organization\n",
      "    Definition: CREATE TABLE organization (\n",
      "\"continent\" text,\n",
      "\"homepage\" text,\n",
      "\"name\" text,\n",
      "\"oid\" int,\n",
      "primary key(\"oid\")\n",
      ");\n",
      "  Table: publication_keyword\n",
      "    Definition: CREATE TABLE publication_keyword (\n",
      "\"pid\" int,\n",
      "\"kid\" int,\n",
      "primary key (\"kid\", \"pid\"),\n",
      "foreign key(\"pid\") references \"publication\"(\"pid\"),\n",
      "foreign key(\"kid\") references \"keyword\"(\"kid\")\n",
      ");\n",
      "  Table: writes\n",
      "    Definition: CREATE TABLE writes (\n",
      "\"aid\" int,\n",
      "\"pid\" int,\n",
      "primary key (\"aid\", \"pid\"),\n",
      "foreign key(\"pid\") references \"publication\"(\"pid\"),\n",
      "foreign key(\"aid\") references \"author\"(\"aid\")\n",
      ");\n",
      "  Table: cite\n",
      "    Definition: CREATE TABLE cite (\n",
      "\"cited\" int,\n",
      "\"citing\"  int,\n",
      "foreign key(\"cited\") references \"publication\"(\"pid\"),\n",
      "foreign key(\"citing\") references \"publication\"(\"pid\")\n",
      ");\n"
     ]
    }
   ],
   "source": [
    "file_key = 'database_parsed_schemas.json'  # replace with your actual file path\n",
    "\n",
    "# Load the file from S3\n",
    "obj = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n",
    "all_schemas = json.load(obj['Body'])\n",
    "\n",
    "# Variable to control how many schemas to print\n",
    "num_databases_to_print = 1\n",
    "\n",
    "# Iterate and print first `num_schemas_to_print` schemas\n",
    "for i, (subfolder, schemas) in enumerate(all_schemas.items()):\n",
    "    if i >= num_databases_to_print:\n",
    "        break \n",
    "    print(f\"Subfolder: {subfolder}\")\n",
    "    for table_name, table_definition in schemas.items():\n",
    "        print(f\"  Table: {table_name}\")\n",
    "        print(f\"    Definition: {table_definition}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f746e176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of databases: 148\n",
      "total number of unique databases: 148\n",
      "total number of tables: 749\n",
      "total number of unique tables: 575\n"
     ]
    }
   ],
   "source": [
    "list_of_databases, list_of_tables, list_of_columns = [], [], []\n",
    "for database in all_schemas:\n",
    "    list_of_databases.append(database)\n",
    "    for table in all_schemas[database]:\n",
    "        list_of_tables.append(table)\n",
    "            \n",
    "print('total number of databases: {}'.format(len(list_of_databases)))\n",
    "print('total number of unique databases: {}'.format(len(list(set(list_of_databases)))))\n",
    "print('total number of tables: {}'.format(len(list_of_tables)))\n",
    "print('total number of unique tables: {}'.format(len(list(set(list_of_tables)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059930d7",
   "metadata": {},
   "source": [
    "### Save databases, tables, columns in 3 separate json files and upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5c6dd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# import json\n",
    "\n",
    "# # Initialize the S3 client\n",
    "# s3 = boto3.client('s3')\n",
    "\n",
    "# # S3 bucket details\n",
    "# bucket_name = 'sagemaker-studio-423623869859-3no3d9ie4hx'\n",
    "\n",
    "# # Assume all_schemas already exists, structured as {database_name: {table_name: [column_names]}}\n",
    "# # Initialize dictionaries for databases, tables, and columns\n",
    "# databases = {database_name: None for database_name in all_schemas.keys()}\n",
    "# tables = {f\"{database_name}.{table_name}\": None for database_name, tables in all_schemas.items() for table_name in tables.keys()}\n",
    "# columns = {f\"{database_name}.{table_name}.{column_name}\": None for database_name, tables in all_schemas.items() for table_name, column_names in tables.items() for column_name in column_names}\n",
    "\n",
    "# # Convert the dictionaries to JSON format\n",
    "# databases_json = json.dumps(databases, indent=4)\n",
    "# tables_json = json.dumps(tables, indent=4)\n",
    "# columns_json = json.dumps(columns, indent=4)\n",
    "\n",
    "# # Define S3 keys for each file\n",
    "# s3_keys = {\n",
    "#     \"databases.json\": databases_json,\n",
    "#     \"tables.json\": tables_json,\n",
    "#     \"columns.json\": columns_json\n",
    "# }\n",
    "\n",
    "# # Save each dictionary to the S3 bucket as a JSON file\n",
    "# for filename, data in s3_keys.items():\n",
    "#     s3.put_object(Bucket=bucket_name, Key=filename, Body=data)\n",
    "#     print(f\"{filename} saved to s3://{bucket_name}/{filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "128331fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(databases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5ed7915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8ccb657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "261df59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4497b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0dd12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
